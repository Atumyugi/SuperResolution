{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRCNN training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as dataf\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'train_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14901, 32, 32, 3)\n",
      "(14901, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    " with h5py.File(file, 'r') as hf:\n",
    "        data = np.array(hf.get('data'))\n",
    "        label = np.array(hf.get('label'))\n",
    "        print(data.shape)\n",
    "        print(label.shape)\n",
    "        #train_data = np.transpose(data, (0, 2, 3, 1))  #改为(14901,32,32,1)\n",
    "        #train_label = np.transpose(label, (0, 2, 3, 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,128,kernel_size=9),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128,64,kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64,1,kernel_size=5),\n",
    "            \n",
    "            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SRCNN()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(9, 9), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 20, 20]          10,496\n",
      "              ReLU-2          [-1, 128, 20, 20]               0\n",
      "            Conv2d-3           [-1, 64, 20, 20]           8,256\n",
      "              ReLU-4           [-1, 64, 20, 20]               0\n",
      "            Conv2d-5            [-1, 1, 16, 16]           1,601\n",
      "================================================================\n",
      "Total params: 20,353\n",
      "Trainable params: 20,353\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.17\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 1.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(1,28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoches = 1  #200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(data) \n",
    "train_data = torch.tensor(train_data)\n",
    "train_label = torch.from_numpy(label)\n",
    "train_label = torch.tensor(train_label)\n",
    "\n",
    "print(train_data.shape,train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataf.TensorDataset(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = dataf.DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(loader)\n",
    "datas,labels = dataiter.next()\n",
    "npimg = datas[0,:,:,:].numpy()\n",
    "npimg = np.reshape(npimg,(32,32))\n",
    "plt.imshow(npimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.utils.make_grid(datas)  #将32个batch的MNIST拼成一个图像\n",
    "npimg = img.numpy()\n",
    "np.shape(npimg)\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0))) # (channel,pixel,pixel)-> (pixel,pixel,channel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoches):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i,data in enumerate(loader,1):\n",
    "        lr_img,hr_img = data\n",
    "        #print(type(lr_img),type(hr_img))  <class 'torch.Tensor'>\n",
    "        # print(lr_img.shape)   torch.Size([32, 1, 32, 32])\n",
    "        # print(hr_img.shape)   torch.Size([32, 1, 20, 20])\n",
    "        lr_img = torch.tensor(lr_img,requires_grad = True)\n",
    "        \n",
    "        # forward\n",
    "        out = model(lr_img)\n",
    "        mse_loss = loss(out,hr_img)\n",
    "        running_loss += mse_loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mse_loss.backward()\n",
    "        optimizer.step()\n",
    "        #if i%1000 == 0:\n",
    "        #    print('[{}/{}] Loss: {:.6f}'.format(\n",
    "        #        epoch + 1, epoches, running_loss))\n",
    "    print('Finish {} epoch, Loss: {:.6f}'.format(\n",
    "        epoch + 1, running_loss ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg = 'Test/Set14/flowers.bmp'\n",
    "img = cv2.imread(testimg,cv2.IMREAD_COLOR)\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = img[:,:,0]\n",
    "img = torch.from_numpy(img)\n",
    "img = torch.tensor(img,requires_grad=True,dtype = torch.float)\n",
    "img = img.view(1,1,362,500)\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npimg = out[0,:,:,:].detach().numpy()\n",
    "npimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npimg = np.reshape(npimg,(350,488))\n",
    "np.shape(npimg)\n",
    "plt.imshow(npimg,cmap = 'gray')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
